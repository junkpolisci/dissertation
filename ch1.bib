
@book{dougherty2011,
	address = {Oxford},
	edition = {Fourth},
	title = {Introduction to {Econometrics}},
	publisher = {Oxford University Press},
	author = {Dougherty, Christian},
	year = {2011}
}

@article{piazza2012,
	title = {Types of {Minority} {Discrimination} and {Terrorism}},
	volume = {29},
	number = {5},
	journal = {Conflict Management and Peace Science},
	author = {Piazza, James A.},
	year = {2012},
	pages = {521--546},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\L2QXWA9L\\Piazza - 2012 - Types of Minority Discrimination and Terrorism.pdf:application/pdf}
}

@article{enders2011,
	title = {Domestic versus {Transnational} {Terrorism}: {Data}, {Decomposition}, and {Dynamics}},
	volume = {48},
	number = {3},
	journal = {Journal of Peace Research},
	author = {Enders, Walter and Sandler, Todd and Gaibulloev, Khusrav},
	year = {2011},
	pages = {319--337}
}

@article{li2005,
	title = {Does {Democracy} {Promote} or {Reduce} {Transnational} {Terrorist} {Incidents}?},
	volume = {49},
	number = {2},
	journal = {The Journal of Conflict Resolution},
	author = {Li, Quan},
	month = apr,
	year = {2005},
	pages = {278--297},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\V2GGK9YZ\\Li - 2005 - Does Democracy Promote or Reduce Transnational Ter.pdf:application/pdf}
}

@article{berrebi2006,
	title = {On {Terrorism} and {Electoral} {Outcomes}: {Theory} and {Evidence} from the {Israeli}-{Palestinian} {Conflict}},
	volume = {50},
	issn = {0022-0027},
	shorttitle = {On {Terrorism} and {Electoral} {Outcomes}},
	url = {http://www.jstor.org/stable/27638530},
	abstract = {This article investigates the interaction between terror attacks and electoral outcomes in Israel. The authors analyze a dynamic model of reputation that captures the salient characteristics of this conflict. The equilibrium of the theoretical model generates two precise empirical predictions about the interaction between terrorism and electoral outcomes. First, the relative support for the right-wing party is expected to increase after periods with high levels of terrorism and to decrease after periods of relative calm. Second, the expected level of terrorism is higher when the left-wing party is in office than it is during the term of the right-wing party. The authors test these hypotheses by using a newly created data set on terrorist attacks in Israel between 1990 and 2003. The first hypothesis is strongly supported by data culled from public opinion polls about the Israeli electorate's political preferences. The second theoretical hypothesis is strongly supported by the three Israeli governments to which the theory can be applied that served during the studied time period.},
	number = {6},
	urldate = {2017-08-10},
	journal = {The Journal of Conflict Resolution},
	author = {Berrebi, Claude and Klor, Esteban F.},
	year = {2006},
	pages = {899--925},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\J8KTVRS3\\Berrebi and Klor - 2006 - On Terrorism and Electoral Outcomes Theory and Ev.pdf:application/pdf}
}

@article{aksoy2014,
	title = {Elections and the {Timing} of {Terrorist} {Attacks}},
	volume = {76},
	issn = {00223816},
	url = {http://proxy.lib.uiowa.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=97931513},
	doi = {10.1017/S0022381614000504},
	number = {4},
	urldate = {2017-08-16},
	journal = {Journal of Politics},
	author = {Aksoy, Deniz},
	month = oct,
	year = {2014},
	pages = {899--913},
	file = {EBSCO Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\A32ZVPV4\\Aksoy - 2014 - Elections and the Timing of Terrorist Attacks.pdf:application/pdf}
}

@article{eubank1994,
	title = {Does democracy encourage terrorism?},
	volume = {6},
	issn = {0954-6553},
	url = {http://dx.doi.org/10.1080/09546559408427271},
	doi = {10.1080/09546559408427271},
	abstract = {The question of the linkage of democratic forms of government with the incidence of terrorist violence is explored. Distinguishing between the presence of terrorist groups in a nation and violent terrorist events, and using multiple indicators of democratic development, evidence is presented clearly linking democracy with the presence of terrorist groups. Terrorist groups are less likely to be found in non‐democratic settings than in democratic ones.},
	number = {4},
	urldate = {2017-10-10},
	journal = {Terrorism and Political Violence},
	author = {Eubank, William Lee and Weinberg, Leonard},
	month = dec,
	year = {1994},
	pages = {417--435},
	file = {Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\DL9FWXBK\\09546559408427271.html:text/html}
}

@article{chenoweth2010,
	title = {Democratic {Competition} and {Terrorist} {Activity}},
	volume = {72},
	issn = {0022-3816},
	url = {http://www.jstor.org/stable/10.1017/s0022381609990442},
	doi = {10.1017/s0022381609990442},
	abstract = {Why is terrorist activity more prevalent in democracies than in nondemocracies? I argue that the main motivation for terrorist attacks in democracies is intergroup dynamics, with terrorist groups of various ideologies competing with one another for limited political influence. I conduct a cross-national, longitudinal analysis of 119 countries for the period 1975–97, using political competition as the key independent variable and the number of transnational terrorist incidents originating in the country as the dependent variable. I find preliminary support for the hypothesis that intergroup competition, motivated by the competition of the political regime, explains an increase in terrorist incidents originating in a state. Evidence also reveals a positive relationship between political competition and the number of terrorist groups that emerge within a state and a positive relationship between the density of domestic interest group participation and terrorist activity. Officials should consider intergroup dynamics to predict terrorist activities and derive effective counterterrorism policies.},
	number = {1},
	urldate = {2017-10-16},
	journal = {The Journal of Politics},
	author = {Chenoweth, Erica},
	year = {2010},
	pages = {16--30},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\2MS97H3N\\Chenoweth - 2010 - Democratic Competition and Terrorist Activity.pdf:application/pdf}
}

@book{krueger2007,
	address = {Princeton, N.J.},
	series = {Lionel {Robbins} lectures},
	title = {What makes a terrorist: economics and the roots of terrorism},
	isbn = {978-0-691-13438-3},
	abstract = {Many popular ideas about terrorists and why they seek to harm us are fueled by falsehoods and misinformation. Leading politicians and scholars have argued that poverty and lack of education breed terrorism, despite the wealth of evidence showing that most terrorists come from middle-class, and often college-educated, backgrounds. In What Makes a Terrorist, Alan Krueger argues that if we are to correctly assess the root causes of terrorism and successfully address the threat, we must think more like economists do. Krueger is an influential economist who has applied rigorous statistical analysis to a range of tough issues, from the minimum wage and education to the occurrence of hate crimes. In this book, he explains why our tactics in the fight against terrorism must be based on more than anecdote and speculation. Krueger closely examines the factors that motivate individuals to participate in terrorism, drawing inferences from terrorists' own backgrounds and the economic, social, and political conditions in the societies from which they come. He describes which countries are the most likely breeding grounds for terrorists, and which ones are most likely to be their targets. Krueger addresses the economic and psychological consequences of terrorism. He puts the terrorist threat squarely into perspective, revealing how our nation's sizeable economy is diverse and resilient enough to withstand the comparatively limited effects of most terrorist strikes. And he calls on the media to be more responsible in reporting on terrorism. What Makes a Terrorist brings needed clarity to one of the greatest challenges of our time.},
	language = {eng},
	publisher = {Princeton University Press},
	author = {Krueger, Alan B.},
	year = {2007},
	keywords = {Terrorism, Terrorism Economic aspects, Terrorists}
}

@article{geddes2014,
	title = {Autocratic {Breakdown} and {Regime} {Transitions}: {A} {New} {Data} {Set}},
	volume = {12},
	issn = {1537-5927, 1541-0986},
	shorttitle = {Autocratic {Breakdown} and {Regime} {Transitions}},
	url = {https://www.cambridge.org/core/journals/perspectives-on-politics/article/autocratic-breakdown-and-regime-transitions-a-new-data-set/EBDB9E5E64CF899AD50B9ACC630B593F},
	doi = {10.1017/S1537592714000851},
	abstract = {When the leader of an autocratic regime loses power, one of three things happens. The incumbent leadership group is replaced by democratically elected leaders. Someone from the incumbent leadership group replaces him, and the regime persists. Or the incumbent leadership group loses control to a different group that replaces it with a new autocracy. Much scholarship exists on the first kind of transition, but little on transitions from one autocracy to another, though they make up about half of all regime changes. We introduce a new data set that facilitates the investigation of all three kinds of transition. It provides transition information for the 280 autocratic regimes in existence from 1946 to 2010. The data identify how regimes exit power, how much violence occurs during transitions, and whether the regimes that precede and succeed them are autocratic. We explain the data set and show how it differs from currently available data. The new data identify autocratic regime breakdowns regardless of whether the country democratizes, which makes possible the investigation of why the ouster of dictators sometimes leads to democracy but often does not, and many other questions. We present a number of examples to highlight how the new data can be used to explore questions about why dictators start wars and why autocratic breakdown sometimes results in the establishment of a new autocratic regime rather than democratization. We discuss the implications of these findings for the Arab Spring.},
	number = {2},
	urldate = {2018-01-03},
	journal = {Perspectives on Politics},
	author = {Geddes, Barbara and Wright, Joseph and Frantz, Erica},
	month = jun,
	year = {2014},
	pages = {313--331},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\QIPX5CNX\\Geddes et al. - 2014 - Autocratic Breakdown and Regime Transitions A New.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\8Y777M9Z\\EBDB9E5E64CF899AD50B9ACC630B593F.html:text/html}
}

@article{young2013,
	title = {Repression, {Dissent}, and the {Onset} of {Civil} {War}},
	volume = {66},
	issn = {1065-9129},
	url = {http://www.jstor.org/stable/23563162},
	abstract = {The prevailing scholarly wisdom is that weak states, or resource-poor states, are the most prone to civil war. Yet many weak states never experience civil war. Why then are some weak states prone to civil war while others are not? The author offers a theory that explains how dissidents and states interact to jointly produce civil war. In sum, states that repress their citizens are the most likely to kill citizens and to generate dissident violence. This insight resolves an academic puzzle and when tested provides a model with better predictive ability than previous models.},
	number = {3},
	urldate = {2018-03-14},
	journal = {Political Research Quarterly},
	author = {Young, Joseph K.},
	year = {2013},
	pages = {516--532},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\SAP7XGMG\\Young - 2013 - Repression, Dissent, and the Onset of Civil War.pdf:application/pdf}
}

@article{collier2004,
	title = {Greed and {Grievance} in {Civil} {War}},
	volume = {56},
	issn = {0030-7653},
	url = {http://www.jstor.org/stable/3488799},
	abstract = {We investigate the causes of civil war, using a new data set of wars during 1960-99. Rebellion may be explained by atypically severe grievances, such as high inequality, a lack of political rights, or ethnic and religious divisions in society. Alternatively, it might be explained by atypical opportunities for building a rebel organization. While it is difficult to find proxies for grievances and opportunities, we find that political and social variables that are most obviously related to grievances have little explanatory power. By contrast, economic variables, which could proxy some grievances but are perhaps more obviously related to the viability of rebellion, provide considerably more explanatory power.},
	number = {4},
	urldate = {2018-05-22},
	journal = {Oxford Economic Papers},
	author = {Collier, Paul and Hoeffler, Anke},
	year = {2004},
	pages = {563--595},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\CAEPXVKL\\Collier and Hoeffler - 2004 - Greed and Grievance in Civil War.pdf:application/pdf}
}

@article{schrodt2014,
	title = {Seven deadly sins of contemporary quantitative political analysis},
	volume = {51},
	issn = {0022-3433},
	url = {https://doi.org/10.1177/0022343313499597},
	doi = {10.1177/0022343313499597},
	abstract = {A combination of technological change, methodological drift and a certain degree of intellectual sloth, particularly with respect to philosophy of science, has allowed contemporary quantitative political analysis to accumulate a series of dysfunctional habits that have rendered much of contemporary research more or less meaningless. I identify these ‘seven deadly sins’ as: Garbage can models that ignore the effects of collinearity; Pre-scientific explanation in the absence of prediction; Excessive reanalysis of a small number of datasets; Using complex methods without understanding the underlying assumptions; Interpreting frequentist statistics as if they were Bayesian; A linear statistical monoculture that fails to consider alternative structures; Confusing statistical controls and experimental controls. The answer to these problems is not to abandon quantitative approaches, but rather engage in solid, thoughtful, original work driven by an appreciation of both theory and data. The article closes with suggestions for changes in current practice that might serve to ameliorate some of these problems.},
	language = {en},
	number = {2},
	urldate = {2018-08-19},
	journal = {Journal of Peace Research},
	author = {Schrodt, Philip A},
	month = mar,
	year = {2014},
	pages = {287--300},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\R8NPD93R\\Schrodt - 2014 - Seven deadly sins of contemporary quantitative pol.pdf:application/pdf}
}

@article{fearon2003,
	title = {Ethnicity, {Insurgency}, and {Civil} {War}},
	volume = {97},
	issn = {1537-5943, 0003-0554},
	url = {http://www.cambridge.org/core/journals/american-political-science-review/article/ethnicity-insurgency-and-civil-war/B1D5D0E7C782483C5D7E102A61AD6605},
	doi = {10.1017/S0003055403000534},
	abstract = {An influential conventional wisdom holds that civil wars proliferated rapidly with the end of the Cold War and that the root cause of many or most of these has been ethnic and religious antagonisms. We show that the current prevalence of internal war is mainly the result of a steady accumulation of protracted conflicts since the 1950s and 1960s rather than a sudden change associated with a new, post-Cold War international system. We also find that after controlling for per capita income, more ethnically or religiously diverse countries have been no more likely to experience significant civil violence in this period. We argue for understanding civil war in this period in terms of insurgency or rural guerrilla warfare, a particular form of military practice that can be harnessed to diverse political agendas. The factors that explain which countries have been at risk for civil war are not their ethnic or religious characteristics but rather the conditions that favor insurgency. These include poverty—which marks financially and bureaucratically weak states and also favors rebel recruitment—political instability, rough terrain, and large populations.We wish to thank the many people who provided comments on earlier versions of this paper in a series of seminar presentations. The authors also gratefully acknowledge the support of the National Science Foundation (Grants SES-9876477 and SES-9876530); support from the Center for Advanced Study in the Behavioral Sciences with funds from the William and Flora Hewlett Foundation; valuable research assistance from Ebru Erdem, Nikolay Marinov, Quinn Mecham, David Patel, and TQ Shang; sharing of data by Paul Collier.},
	language = {en},
	number = {1},
	urldate = {2018-08-19},
	journal = {American Political Science Review},
	author = {Fearon, James D. and Laitin, David D.},
	month = feb,
	year = {2003},
	pages = {75--90},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\K6A29QFJ\\Fearon and Laitin - 2003 - Ethnicity, Insurgency, and Civil War.pdf:application/pdf;JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\MUS3PKDG\\Fearon and Laitin - 2003 - Ethnicity, Insurgency, and Civil War.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\U768ACBH\\B1D5D0E7C782483C5D7E102A61AD6605.html:text/html}
}

@article{bleek2014,
	title = {Security {Guarantees} and {Allied} {Nuclear} {Proliferation}},
	volume = {58},
	issn = {0022-0027},
	url = {https://doi.org/10.1177/0022002713509050},
	doi = {10.1177/0022002713509050},
	abstract = {As Iran continues its apparent pursuit of a nuclear weapons breakout capability and North Korea resists efforts to roll back its proliferation, policy makers in Washington eager to prevent further proliferation in both regions regard security guarantees to allies as crucial tools. But recent scholarship calls into question whether security guarantees ameliorate proliferation risks. Relying on a combination of large-N quantitative analysis and a case study of South Korea from the late 1960s to the mid-1980s, this article argues that, consistent with policy makers’ conventional wisdom, security guarantees significantly reduce proliferation proclivity among their recipients.},
	language = {en},
	number = {3},
	urldate = {2018-08-21},
	journal = {Journal of Conflict Resolution},
	author = {Bleek, Philipp C. and Lorber, Eric B.},
	year = {2014},
	pages = {429--454},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\JI3IDBXM\\Bleek and Lorber - 2014 - Security Guarantees and Allied Nuclear Proliferati.pdf:application/pdf}
}

@article{daxecker2013,
	title = {Insurgents of the {Sea}: {Institutional} and {Economic} {Opportunities} for {Maritime} {Piracy}},
	volume = {57},
	issn = {0022-0027},
	shorttitle = {Insurgents of the {Sea}},
	url = {https://doi.org/10.1177/0022002712453709},
	doi = {10.1177/0022002712453709},
	abstract = {While piracy may evoke romanticized visions of swashbuckling, rum swigging, and skirt chasing pirates hoisting the Jolly Roger, maritime piracy has changed substantially by taking advantage of modernization and substantial upgrading of the weapons, vessels, and weapons it employs. In addition, as documented by the International Maritime Bureau (IMB), the frequency of pirate attacks has increased significantly, with more than 2,600 piracy incidents occurring since 2004. The authors argue that piracy is a result of permissive institutional environments and the lack of legal forms of employment in states’ fishing sectors. The authors investigate these arguments empirically using data for all countries with coastlines in the 1995–2007 period. The empirical analyses show that state weakness and reductions in fisheries production values affect piracy as expected. These findings suggest that international efforts in combating piracy should center on improving the institutional environments and labor opportunities driving maritime piracy.},
	language = {en},
	number = {6},
	urldate = {2018-10-30},
	journal = {Journal of Conflict Resolution},
	author = {Daxecker, Ursula and Prins, Brandon},
	month = dec,
	year = {2013},
	pages = {940--965},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\4L7IZT87\\Daxecker and Prins - 2013 - Insurgents of the Sea Institutional and Economic .pdf:application/pdf}
}

@article{nardulli2015,
	title = {A {Progressive} {Supervised}-learning {Approach} to {Generating} {Rich} {Civil} {Strife} {Data}:},
	shorttitle = {A {Progressive} {Supervised}-learning {Approach} to {Generating} {Rich} {Civil} {Strife} {Data}},
	url = {https://journals.sagepub.com/doi/pdf/10.1177/0081175015581378},
	doi = {10.1177/0081175015581378},
	abstract = {“Big data” in the form of unstructured text pose challenges and opportunities to social scientists committed to advancing research frontiers. Because machine-based and human-centric approaches to content analysis have different strengths for extracting information from unstructured text, the authors argue for a collaborative, hybrid approach that combines their comparative advantages. The notion of a progressive supervised-learning approach that combines data science techniques and human coders is developed and illustrated using the Social, Political and Economic Event Database (SPEED) project’s Societal Stability Protocol. SPEED’s rich event data on civil strife reveal that conventional machine-based approaches for generating event data miss a great deal of within-category variance, while conventional human-based efforts to categorize periods of civil war or political instability routinely misspecify periods of calm and unrest. To demonstrate the potential of hybrid data collection methods, SPEED data on...},
	language = {en},
	urldate = {2018-11-20},
	journal = {Sociological Methodology},
	author = {Nardulli, Peter F. and Althaus, Scott L. and Hayes, Matthew},
	year = {2015},
	file = {Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\B8XFRREL\\0081175015581378.html:text/html}
}

@article{schmid1992,
	title = {Terrorism and democracy},
	volume = {4},
	issn = {0954-6553},
	url = {https://doi.org/10.1080/09546559208427173},
	doi = {10.1080/09546559208427173},
	abstract = {When there is a confrontation between the absolute politics of terrorism and the compromising politics of democracies, the former seems to be in a position of advantage. This essay discusses the strengths of democracies (non‐violent change through elections, open criticism in and by the media, courts that protect the weak against the strong) as well as their weaknesses (freedom of movement and association, abundance of accessible targets and a legal system that requires solid proof). The weaknesses of democratic societies are increased by some features of the market system (it not only increases wealth but also inequality, sells weapons to supporters of terrorism, manages their banking and offers them access to the media through the commercial basis of the concept of news value). Ultimately, the struggle between terrorism and democracy is one for legitimacy and maintaining the latter is strategically more important for democratic governments than winning short‐term victories through tactical ‘quick fixes’ which might seem effective but turn democracies into something that begins to mirror the terrorist opponent.},
	number = {4},
	urldate = {2019-02-27},
	journal = {Terrorism and Political Violence},
	author = {Schmid, Alex P.},
	month = dec,
	year = {1992},
	pages = {14--25},
	file = {Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\N9SM4YHI\\09546559208427173.html:text/html}
}

@article{colaresi2017,
	title = {Do the robot: {Lessons} from machine learning to improve conflict forecasting},
	volume = {54},
	issn = {0022-3433},
	shorttitle = {Do the robot},
	url = {https://doi.org/10.1177/0022343316682065},
	doi = {10.1177/0022343316682065},
	abstract = {Increasingly, scholars interested in understanding conflict processes have turned to evaluating out-of-sample forecasts to judge and compare the usefulness of their models. Research in this vein has made significant progress in identifying and avoiding the problem of overfitting sample data. Yet there has been less research providing strategies and tools to practically improve the out-of-sample performance of existing models and connect forecasting improvement to the goal of theory development in conflict studies. In this article, we fill this void by building on lessons from machine learning research. We highlight a set of iterative tasks, which David Blei terms ‘Box’s loop’, that can be summarized as build, compute, critique, and think. While the initial steps of Box’s loop will be familiar to researchers, the underutilized process of model criticism allows researchers to iteratively learn more useful representations of the data generation process from the discrepancies between the trained model and held-out data. To benefit from iterative model criticism, we advise researchers not only to split their available data into separate training and test sets, but also sample from their training data to allow for iterative model development, as is common in machine learning applications. Since practical tools for model criticism in particular are underdeveloped, we also provide software for new visualizations that build upon already existing tools. We use models of civil war onset to provide an illustration of how our machine learning-inspired research design can simultaneously improve out-of-sample forecasting performance and identify useful theoretical contributions. We believe these research strategies can complement existing designs to accelerate innovations across conflict processes.},
	language = {en},
	number = {2},
	urldate = {2019-03-05},
	journal = {Journal of Peace Research},
	author = {Colaresi, Michael and Mahmood, Zuhaib},
	month = mar,
	year = {2017},
	pages = {193--214},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\YPPBXVYD\\Colaresi and Mahmood - 2017 - Do the robot Lessons from machine learning to imp.pdf:application/pdf}
}

@article{basuchoudhary2018,
	title = {Predicting {Terrorism} with {Machine} {Learning}: {Lessons} from “{Predicting} {Terrorism}: {A} {Machine} {Learning} {Approach}”},
	volume = {24},
	issn = {1554-8597},
	shorttitle = {Predicting {Terrorism} with {Machine} {Learning}},
	url = {http://www.degruyter.com/view/j/peps.2018.24.issue-4/peps-2018-0040/peps-2018-0040.xml},
	doi = {10.1515/peps-2018-0040},
	abstract = {This paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research.},
	number = {4},
	urldate = {2019-03-05},
	journal = {Peace Economics, Peace Science and Public Policy},
	author = {Basuchoudhary, Atin and Bang, James T.},
	year = {2018},
	keywords = {Artificial Intelligence, Machine Learning, predicting terrorism, predictive analytics, terrorism risk},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\UL64T3LV\\Basuchoudhary and Bang - 2018 - Predicting Terrorism with Machine Learning Lesson.pdf:application/pdf}
}

@article{gill1999,
	title = {The {Insignificance} of {Null} {Hypothesis} {Significance} {Testing}},
	volume = {52},
	issn = {1065-9129},
	url = {https://doi.org/10.1177/106591299905200309},
	doi = {10.1177/106591299905200309},
	abstract = {The current method of hypothesis testing in the social sciences is under intense criticism, yet most political scientists are unaware of the important issues being raised. Criticisms focus on the construction and interpretation of a procedure that has dominated the reporting of empirical results for over fifty years. There is evidence that null hypothesis significance testing as practiced in political science is deeply flawed and widely misunderstood. This is important since most empirical work argues the value of findings through the use of the null hypothesis significance test. In this article I review the history of the null hypothesis significance testing paradigm in the social sciences and discuss major problems, some of which are logical inconsistencies while others are more interpretive in nature. I suggest alter native techniques to convey effectively the importance of data-analytic findings. These recommendations are illustrated with examples using empirical political science publications.},
	language = {en},
	number = {3},
	urldate = {2019-03-06},
	journal = {Political Research Quarterly},
	author = {Gill, Jeff},
	month = sep,
	year = {1999},
	pages = {647--674},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\GPE5FRC4\\Gill - 1999 - The Insignificance of Null Hypothesis Significance.pdf:application/pdf}
}

@article{greene2018a,
	title = {Machine {Learning} {Human} {Rights} and {Wrongs}: {How} the {Successes} and {Failures} of {Supervised} {Learning} {Algorithms} {Can} {Inform} the {Debate} {About} {Information} {Effects}},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Machine {Learning} {Human} {Rights} and {Wrongs}},
	url = {http://www.cambridge.org/core/journals/political-analysis/article/machine-learning-human-rights-and-wrongs-how-the-successes-and-failures-of-supervised-learning-algorithms-can-inform-the-debate-about-information-effects/C4CB3FC4383A50129F6A0F0809BA2452},
	doi = {10.1017/pan.2018.11},
	abstract = {There is an ongoing debate about whether human rights standards have changed over the last 30 years. The evidence for or against this shift relies upon indicators created by human coders reading the texts of human rights reports. To help resolve this debate, we suggest translating the question of changing standards into a supervised learning problem. From this perspective, the application of consistent standards over time implies a time-constant mapping from the textual features in reports to the human coded scores. Alternatively, if the meaning of abuses have evolved over time, then the same textual features will be labeled with different numerical scores at distinct times. Of course, while the mapping from natural language to numerical human rights score is a highly complicated function, we show that these two distinct data generation processes imply divergent overall patterns of accuracy when we train a wide variety of algorithms on older versus newer sets of observations to learn how to automatically label texts with scores. Our results are consistent with the expectation that standards of human rights have changed over time.},
	language = {en},
	urldate = {2019-03-06},
	journal = {Political Analysis},
	author = {Greene, Kevin T. and Park, Baekkwan and Colaresi, Michael},
	year = {2018},
	keywords = {forecasting, learning, statistical analysis of texts, time series},
	pages = {1--8},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\DYT5LLI2\\Greene et al. - Machine Learning Human Rights and Wrongs How the .pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\7S3IDUG8\\C4CB3FC4383A50129F6A0F0809BA2452.html:text/html}
}

@article{mueller2018,
	title = {Reading {Between} the {Lines}: {Prediction} of {Political} {Violence} {Using} {Newspaper} {Text}},
	volume = {112},
	issn = {0003-0554, 1537-5943},
	shorttitle = {Reading {Between} the {Lines}},
	url = {http://www.cambridge.org/core/journals/american-political-science-review/article/reading-between-the-lines-prediction-of-political-violence-using-newspaper-text/4EABB473AFE18F157EEDE4339F34ABB0},
	doi = {10.1017/S0003055417000570},
	abstract = {This article provides a new methodology to predict armed conflict by using newspaper text. Through machine learning, vast quantities of newspaper text are reduced to interpretable topics. These topics are then used in panel regressions to predict the onset of conflict. We propose the use of the within-country variation of these topics to predict the timing of conflict. This allows us to avoid the tendency of predicting conflict only in countries where it occurred before. We show that the within-country variation of topics is a good predictor of conflict and becomes particularly useful when risk in previously peaceful countries arises. Two aspects seem to be responsible for these features. Topics provide depth because they consist of changing, long lists of terms that make them able to capture the changing context of conflict. At the same time, topics provide width because they are summaries of the full text, including stabilizing factors.},
	language = {en},
	number = {2},
	urldate = {2019-03-14},
	journal = {American Political Science Review},
	author = {Mueller, Hannes and Rauh, Christopher},
	month = may,
	year = {2018},
	pages = {358--375},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\4E5HQUBW\\Mueller and Rauh - 2018 - Reading Between the Lines Prediction of Political.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\HRJN3634\\4EABB473AFE18F157EEDE4339F34ABB0.html:text/html}
}

@article{minhas2015,
	title = {Mining texts to efficiently generate global data on political regime types},
	volume = {2},
	issn = {2053-1680},
	url = {https://doi.org/10.1177/2053168015589217},
	doi = {10.1177/2053168015589217},
	abstract = {We describe the design and results of an experiment in using text-mining and machine-learning techniques to generate annual measures of national political regime types. Valid and reliable measures of countries’ forms of national government are essential to cross-national and dynamic analysis of many phenomena of great interest to political scientists, including civil war, interstate war, democratization, and coups d’état. Unfortunately, traditional measures of regime type are very expensive to produce, and observations for ambiguous cases are often sharply contested. In this project, we train a series of support vector machine (SVM) classifiers to infer regime type from textual data sources. To train the classifiers, we used vectorized textual reports from Freedom House and the State Department as features for a training set of prelabeled regime type data. To validate our SVM classifiers, we compare their predictions in an out-of-sample context, and the performance results across a variety of metrics (accuracy, precision, recall) are very high. The results of this project highlight the ability of these techniques to contribute to producing real-time data sources for use in political science that can also be routinely updated at much lower cost than human-coded data. To this end, we set up a text-processing pipeline that pulls updated textual data from selected sources, conducts feature extraction, and applies supervised machine learning methods to produce measures of regime type. This pipeline, written in Python, can be pulled from the Github repository associated with this project and easily extended as more data becomes available.},
	language = {en},
	number = {3},
	urldate = {2019-03-14},
	journal = {Research \& Politics},
	author = {Minhas, Shahryar and Ulfelder, Jay and Ward, Michael D},
	month = jul,
	year = {2015},
	pages = {2053168015589217},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\WDHEATVM\\Minhas et al. - 2015 - Mining texts to efficiently generate global data o.pdf:application/pdf}
}

@article{hindman2015,
	title = {Building {Better} {Models}: {Prediction}, {Replication}, and {Machine} {Learning} in the {Social} {Sciences}},
	volume = {659},
	issn = {0002-7162},
	shorttitle = {Building {Better} {Models}},
	url = {https://doi.org/10.1177/0002716215570279},
	doi = {10.1177/0002716215570279},
	abstract = {Analytic techniques developed for big data have much broader applications in the social sciences, outperforming standard regression models even—or rather especially—in smaller datasets. This article offers an overview of machine learning methods well-suited to social science problems, including decision trees, dimension reduction methods, nearest neighbor algorithms, support vector models, and penalized regression. In addition to novel algorithms, machine learning places great emphasis on model checking (through holdout samples and cross-validation) and model shrinkage (adjusting predictions toward the mean to reduce overfitting). This article advocates replacing typical regression analyses with two different sorts of models used in concert. A multi-algorithm ensemble approach should be used to determine the noise floor of a given dataset, while simpler methods such as penalized regression or decision trees should be used for theory building and hypothesis testing.},
	language = {en},
	number = {1},
	urldate = {2019-03-14},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	author = {Hindman, Matthew},
	month = may,
	year = {2015},
	pages = {48--62},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\NADRTK7B\\Hindman - 2015 - Building Better Models Prediction, Replication, a.pdf:application/pdf}
}

@article{burscher2015,
	title = {Using {Supervised} {Machine} {Learning} to {Code} {Policy} {Issues}: {Can} {Classifiers} {Generalize} across {Contexts}?},
	volume = {659},
	issn = {0002-7162},
	shorttitle = {Using {Supervised} {Machine} {Learning} to {Code} {Policy} {Issues}},
	url = {https://doi.org/10.1177/0002716215569441},
	doi = {10.1177/0002716215569441},
	abstract = {Content analysis of political communication usually covers large amounts of material and makes the study of dynamics in issue salience a costly enterprise. In this article, we present a supervised machine learning approach for the automatic coding of policy issues, which we apply to news articles and parliamentary questions. Comparing computer-based annotations with human annotations shows that our method approaches the performance of human coders. Furthermore, we investigate the capability of an automatic coding tool, which is based on supervised machine learning, to generalize across contexts. We conclude by highlighting implications for methodological advances and empirical theory testing.},
	language = {en},
	number = {1},
	urldate = {2019-03-14},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	author = {Burscher, Bjorn and Vliegenthart, Rens and De Vreese, Claes H.},
	month = may,
	year = {2015},
	pages = {122--131},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\IYXUSB42\\Burscher et al. - 2015 - Using Supervised Machine Learning to Code Policy I.pdf:application/pdf}
}

@article{croicu2015,
	title = {Improving the selection of news reports for event coding using ensemble classification},
	volume = {2},
	issn = {2053-1680},
	url = {https://doi.org/10.1177/2053168015615596},
	doi = {10.1177/2053168015615596},
	abstract = {Manual coding of political events from news reports is extremely expensive and time-consuming, whereas completely automatic coding has limitations when it comes to the precision and granularity of the data collected. In this paper, we introduce an alternative strategy by establishing a semi-automatic pipeline, where an automatic classification system eliminates irrelevant source material before further coding is done by humans. Our pipeline relies on a high-performance supervised heterogeneous ensemble classifier working on extremely unbalanced training classes. Deployed to the Mass Mobilization on Autocracies database on protest, the system is able to reduce the number of source articles to be human-coded by more than half, while keeping over 90\% of the relevant material.},
	language = {en},
	number = {4},
	urldate = {2019-03-14},
	journal = {Research \& Politics},
	author = {Croicu, Mihai and Weidmann, Nils B},
	month = oct,
	year = {2015},
	pages = {2053168015615596},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\WQBYT66V\\Croicu and Weidmann - 2015 - Improving the selection of news reports for event .pdf:application/pdf}
}

@article{al-zewairi2017,
	title = {Spotting the {Islamist} {Radical} within: {Religious} {Extremists} {Profiling} in the {United} {State}},
	volume = {113},
	issn = {1877-0509},
	shorttitle = {Spotting the {Islamist} {Radical} within},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050917317465},
	doi = {10.1016/j.procs.2017.08.336},
	abstract = {The war on terrorism, radicalism and violent extremism is no longer confined to the battlefield; it has become omnipresent in the recent years with mi…},
	language = {en},
	urldate = {2019-03-14},
	journal = {Procedia Computer Science},
	author = {Al-Zewairi, Malek and Naymat, Ghazi},
	month = jan,
	year = {2017},
	pages = {162--169},
	file = {2017 - Spotting the Islamist Radical within Religious Ex.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\8XRKFESV\\2017 - Spotting the Islamist Radical within Religious Ex.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\NRJ6WHGM\\S1877050917317465.html:text/html}
}

@article{hill2013,
	title = {Modeling terrorism culpability: {An} event-based approach},
	volume = {10},
	issn = {1548-5129},
	shorttitle = {Modeling terrorism culpability},
	url = {https://doi.org/10.1177/1548512912455470},
	doi = {10.1177/1548512912455470},
	abstract = {Recently, researchers have become interested in the issue of assessing culpability for terrorist attacks when no one group claims or multiple groups claim responsibility. Several new methods have been put forward for predicting culpability, traditionally assessed by intelligence analysts, using both machine learning and statistical classification models. These models have had varying degrees of success, with new ensemble classification models performing generally better than traditional statistical techniques. This paper applies a relatively new methodology, Random Forests, to the problem of predicting culpability and compares it to some of the more frequently used statistical classification techniques, including multinomial logistic regression and naïve Bayesian classification. Though generally outperforming other techniques, Random Forests struggles with unbalanced data, performing worse than either of the other models tested in the class with the least information. However, this evaluation of Random Forests for the assessment of terrorism culpability is positive. Implications of the model and comparison to other models are discussed and ways forward are suggested.},
	language = {en},
	number = {2},
	urldate = {2019-03-14},
	journal = {The Journal of Defense Modeling and Simulation},
	author = {Hill, Joshua B and Mabrey, Daniel J and Miller, John M},
	month = apr,
	year = {2013},
	pages = {181--191},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\NPJ54EI2\\Hill et al. - 2013 - Modeling terrorism culpability An event-based app.pdf:application/pdf}
}

@article{ding2017,
	title = {Understanding the dynamics of terrorism events with multiple-discipline datasets and machine learning approach},
	volume = {12},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0179057},
	doi = {10.1371/journal.pone.0179057},
	language = {en},
	number = {6},
	urldate = {2019-03-14},
	journal = {PLOS ONE},
	author = {Ding, Fangyu and Ge, Quansheng and Jiang, Dong and Fu, Jingying and Hao, Mengmeng},
	editor = {Yang, Jinn-Moon},
	month = jun,
	year = {2017},
	pages = {e0179057},
	file = {Ding et al. - 2017 - Understanding the dynamics of terrorism events wit.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\YW3CPLNY\\Ding et al. - 2017 - Understanding the dynamics of terrorism events wit.pdf:application/pdf}
}

@article{fariss2014,
	title = {Respect for {Human} {Rights} has {Improved} {Over} {Time}: {Modeling} the {Changing} {Standard} of {Accountability}},
	volume = {108},
	issn = {0003-0554, 1537-5943},
	shorttitle = {Respect for {Human} {Rights} has {Improved} {Over} {Time}},
	url = {http://www.cambridge.org/core/journals/american-political-science-review/article/respect-for-human-rights-has-improved-over-time-modeling-the-changing-standard-of-accountability/0E7B51BE2CDA4A141779E594FF0F0EFF},
	doi = {10.1017/S0003055414000070},
	abstract = {According to indicators of political repression currently used by scholars, human rights practices have not improved over the past 35 years, despite the spread of human rights norms, better monitoring, and the increasing prevalence of electoral democracy. I argue that this empirical pattern is not an indication of stagnating human rights practices. Instead, it reflects a systematic change in the way monitors, like Amnesty International and the U.S. State Department, encounter and interpret information about abuses. The standard of accountability used to assess state behaviors becomes more stringent as monitors look harder for abuse, look in more places for abuse, and classify more acts as abuse. In this article, I present a new, theoretically informed measurement model, which generates unbiased estimates of repression using existing data. I then show that respect for human rights has improved over time and that the relationship between human rights respect and ratification of the UN Convention Against Torture is positive, which contradicts findings from existing research.},
	language = {en},
	number = {2},
	urldate = {2019-04-22},
	journal = {American Political Science Review},
	author = {Fariss, Christopher J.},
	month = may,
	year = {2014},
	pages = {297--318},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\MKE57ETY\\Fariss - 2014 - Respect for Human Rights has Improved Over Time M.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\EDPHL8SH\\0E7B51BE2CDA4A141779E594FF0F0EFF.html:text/html}
}

@misc{start2018,
	title = {Profiles of {Individual} {Radicalization} in the {United} {States}},
	url = {http://www.start.umd.edu/pirus},
	author = {(START), National Consortium for the Study of Terrorism {and} Responses to Terrorism},
	year = {2018}
}

@inproceedings{pham2018,
	title = {Modeling {The} {Causes} {Of} {Terrorism} {From} {Media} {News}: {An} {Innovative} {Framework} {Connecting} {Impactful} {Events} {With} {Terror} {Incidents}},
	shorttitle = {Modeling {The} {Causes} {Of} {Terrorism} {From} {Media} {News}},
	doi = {10.1109/KSE.2018.8573353},
	abstract = {Terrorism has become an increasingly relevant issue accounting for significant social, economic and political impact. Due to powerful media coverage on the subject, a lot of information is now publicly available, although normally found in an unstructured form. This research aims to better understand the connection between a collection of impactful events, such as external or internal conflicts and military operations, with terror events and its motivations. To this end, a framework was devised, starting with an online news scraper, coupled with machine learning and natural language processing techniques, capable of clustering keywords into the main topics found in the news. The results of these algorithms, in the form of structured data, were later fed to a modeling technique capable of finding, to a certain degree, the connections between topics and terror events. The approach presented in this work adopts a perspective that, to the best of our knowledge, has not been previously seen in specialized literature. Furthermore, this methodology constitutes the groundwork for open source intelligence, capable of being applied to various similar domains like the prediction of political risk index or economic risk index.},
	booktitle = {2018 10th {International} {Conference} on {Knowledge} and {Systems} {Engineering} ({KSE})},
	author = {Pham, T. S. and Hoang, T.},
	month = nov,
	year = {2018},
	keywords = {terrorism, Terrorism, Machine learning, politics, Machine Learning, Machine learning algorithms, learning (artificial intelligence), Data mining, economic impact, external conflicts, Feature extraction, increasingly relevant issue accounting, information retrieval, innovative framework connecting impactful events, internal conflicts, Knowledge engineering, media news, Modeling, natural language processing, natural language processing techniques, online news scraper, Open Source Intelligence, pattern clustering, political impact, powerful media coverage, significant social impact, terror events, terror incidents, text analysis, unstructured form},
	pages = {364--369},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\HTTQNFNE\\8573353.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\JL9CG5C2\\Pham and Hoang - 2018 - Modeling The Causes Of Terrorism From Media News .pdf:application/pdf}
}

@article{boschee2019,
	title = {{ICEWS} {Automated} {Daily} {Event} {Data}},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/QI2T9A},
	doi = {10.7910/DVN/QI2T9A},
	abstract = {Event data consists of coded interactions between socio-political actors (i.e., cooperative or hostile actions between individuals, groups, sectors...},
	language = {en},
	urldate = {2019-06-06},
	author = {Boschee, Elizabeth and Lautenschlager, Jennifer and O'Brien, Sean and Shellman, Steve and Starz, James},
	month = jun,
	year = {2019},
	note = {type: dataset}
}

@article{reeder2018a,
	title = {The {Political} {Geography} of {Rebellion}: {Using} {Event} {Data} to {Identify} {Insurgent} {Territory}, {Preferences}, and {Relocation} {Patterns}},
	volume = {62},
	issn = {0020-8833, 1468-2478},
	shorttitle = {The {Political} {Geography} of {Rebellion}},
	url = {https://academic.oup.com/isq/article/62/3/696/5059898},
	doi = {10.1093/isq/sqy016},
	language = {en},
	number = {3},
	urldate = {2019-06-07},
	journal = {International Studies Quarterly},
	author = {Reeder, Bryce W},
	month = sep,
	year = {2018},
	pages = {696--707},
	file = {Reeder - 2018 - The Political Geography of Rebellion Using Event .pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\GC3WGZS5\\Reeder - 2018 - The Political Geography of Rebellion Using Event .pdf:application/pdf}
}

@article{hadenius2007,
	title = {Pathways from {Authoritarianism}},
	volume = {18},
	issn = {1086-3214},
	url = {http://muse.jhu.edu/article/209112},
	doi = {10.1353/jod.2007.0009},
	abstract = {This paper uses a new typology of authoritarian regimes to explore the extent to which regime type explains the survival (and breakdown) of non-democratic regimes as well as the impact of different types of authoritarian regimes on democratic development. Our results demonstrate that different types of authoritarian regime face different propensities to develop toward democracy. Hence the nature of the authoritarian regime in question deserves to be added to the list of democracy’s essential preconditions. One regime type—the limited multiparty system—stands out as the prime stepping stone to democracy. The fact that this regime type has become the most common form of authoritarianism can be seen as a promising sign for the future.},
	language = {en},
	number = {1},
	urldate = {2019-06-09},
	journal = {Journal of Democracy},
	author = {Hadenius, Axel and Teorell, Jan},
	month = jan,
	year = {2007},
	pages = {143--157},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\SB8B549K\\Hadenius and Teorell - 2007 - Pathways from Authoritarianism.pdf:application/pdf}
}

@article{ward2010a,
	title = {The perils of policy by p-value: {Predicting} civil conflicts},
	volume = {47},
	issn = {0022-3433},
	shorttitle = {The perils of policy by p-value},
	url = {https://doi.org/10.1177/0022343309356491},
	doi = {10.1177/0022343309356491},
	abstract = {Large-n studies of conflict have produced a large number of statistically significant results but little accurate guidance in terms of anticipating the onset of conflict. The authors argue that too much attention has been paid to finding statistically significant relationships, while too little attention has been paid to finding variables that improve our ability to predict civil wars. The result can be a distorted view of what matters most to the onset of conflict. Although these models may not be intended to be predictive models, prescriptions based on these models are generally based on statistical significance, and the predictive attributes of the underlying models are generally ignored. These predictions should not be ignored, but rather need to be heuristically evaluated because they may shed light on the veracity of the models. In this study, the authors conduct a side-by-side comparison of the statistical significance and predictive power of the different variables used in two of the most influential models of civil war. The results provide a clear demonstration of how potentially misleading the traditional focus on statistical significance can be. Until out-of-sample heuristics — especially including predictions — are part of the normal evaluative tools in conflict research, we are unlikely to make sufficient theoretical progress beyond broad statements that point to GDP per capita and population as the major causal factors accounting for civil war onset.},
	language = {en},
	number = {4},
	urldate = {2019-06-09},
	journal = {Journal of Peace Research},
	author = {Ward, Michael D and Greenhill, Brian D and Bakke, Kristin M},
	month = jul,
	year = {2010},
	pages = {363--375},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\WMC7ZRFW\\Ward et al. - 2010 - The perils of policy by p-value Predicting civil .pdf:application/pdf}
}

@article{gleditsch2013,
	title = {Forecasting is difficult, especially about the future: {Using} contentious issues to forecast interstate disputes},
	volume = {50},
	issn = {0022-3433, 1460-3578},
	shorttitle = {Forecasting is difficult, especially about the future},
	url = {http://journals.sagepub.com/doi/10.1177/0022343312449033},
	doi = {10.1177/0022343312449033},
	abstract = {Prediction is an important goal in the study of international conflict, but a large body of research has found that existing statistical models generally have disappointing predictive abilities. We show that most efforts build on models unlikely to be helpful for prediction. Many models essentially ignore the origins of conflict; studies look either at invariant structural features believed to affect the opportunities of conflict, or at factors that are believed to reduce the baseline risk of conflict, without attempting to identify the potential motivations and contentious issues over which conflicts typically arise. Researchers that have considered how contentious issues may motivate conflict and how these can be managed, using the Issues Correlates of War (ICOW) data, have not considered how these features may inform prediction. We assess the risk of dyadic interstate conflict based on the presence of specific contentious issues and conflict management events that may change the conflict potential of these contentious issues. We evaluate to what extent incorporating contentious issues and conflict management can help improve out-of-sample forecasting, as well as advance our understanding of conflict dynamics. Our results provide strong support for the idea that taking into account contentious issues can inform and improve out-of-sample forecasting.},
	language = {en},
	number = {1},
	urldate = {2019-06-10},
	journal = {Journal of Peace Research},
	author = {Gleditsch, Kristian Skrede and Ward, Michael D},
	month = jan,
	year = {2013},
	pages = {17--31},
	file = {Gleditsch and Ward - 2013 - Forecasting is difficult, especially about the fut.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\HFM84HTL\\Gleditsch and Ward - 2013 - Forecasting is difficult, especially about the fut.pdf:application/pdf}
}

@article{muchlinski2016,
	title = {Comparing {Random} {Forest} with {Logistic} {Regression} for {Predicting} {Class}-{Imbalanced} {Civil} {War} {Onset} {Data}},
	volume = {24},
	issn = {1047-1987, 1476-4989},
	url = {http://www.cambridge.org/core/journals/political-analysis/article/comparing-random-forest-with-logistic-regression-for-predicting-classimbalanced-civil-war-onset-data/109E1511378A38BB4B41F721E6017FB1},
	doi = {10.1093/pan/mpv024},
	abstract = {The most commonly used statistical models of civil war onset fail to correctly predict most occurrences of this rare event in out-of-sample data. Statistical methods for the analysis of binary data, such as logistic regression, even in their rare event and regularized forms, perform poorly at prediction. We compare the performance of Random Forests with three versions of logistic regression (classic logistic regression, Firth rare events logistic regression, and L
1-regularized logistic regression), and find that the algorithmic approach provides significantly more accurate predictions of civil war onset in out-of-sample data than any of the logistic regression models. The article discusses these results and the ways in which algorithmic statistical methods like Random Forests can be useful to more accurately predict rare events in conflict data.},
	language = {en},
	number = {1},
	urldate = {2019-06-10},
	journal = {Political Analysis},
	author = {Muchlinski, David and Siroky, David and He, Jingrui and Kocher, Matthew},
	year = {2016},
	pages = {87--103},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\THLYHBLM\\Muchlinski et al. - 2016 - Comparing Random Forest with Logistic Regression f.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\HEVSTYKP\\109E1511378A38BB4B41F721E6017FB1.html:text/html}
}

@article{blair2014,
	title = {Predicting {Local} {Violence}},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=2497153},
	doi = {10.2139/ssrn.2497153},
	abstract = {Riots, murders, lynchings, and other forms of local violence are costly to security forces and society at large. Identifying risk factors and forecasting where local violence is most likely to occur should help allocate scarce peacekeeping and policing resources. Most forecasting exercises of this kind rely on structural or event data, but these have many limitations in the poorest and most war-torn states, where the need for prediction is arguably most urgent. We adopt an alternative approach, applying machine learning techniques to original panel survey data from Liberia to predict collective, interpersonal, and extrajudicial violence two years into the future. We first train our models to predict 2010 local violence using 2008 risk factors, then generate forecasts for 2012 before collecting new data. Our models achieve out-of-sample AUCs ranging from 0.65 to 0.74, depending on our specification of the dependent variable. The models also draw our attention to risk factors different from those typically emphasized in studies aimed at causal inference alone. For example, we find that while ethnic heterogeneity and polarization are reliable predictors of local violence, adverse economic shocks are not. Surprisingly, we also find that the risk of local violence is higher rather than lower in communities where minority and majority ethnic groups share power. These counter-intuitive results illustrate the usefulness of prediction for generating new stylized facts for future research to explain. Ours is one of just two attempts to forecast local violence using survey data, and we conclude by discussing how our approach can be replicated and extended as similar datasets proliferate.},
	language = {en},
	urldate = {2019-06-10},
	journal = {SSRN Electronic Journal},
	author = {Blair, Robert A. and Blattman, Christopher and Hartman, Alexandra},
	year = {2014},
	file = {Blair et al. - 2014 - Predicting Local Violence.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\EB4ZA9XJ\\Blair et al. - 2014 - Predicting Local Violence.pdf:application/pdf}
}

@article{witmer2017,
	title = {Subnational violent conflict forecasts for sub-{Saharan} {Africa}, 2015–65, using climate-sensitive models},
	volume = {54},
	issn = {0022-3433},
	url = {https://doi.org/10.1177/0022343316682064},
	doi = {10.1177/0022343316682064},
	abstract = {How will local violent conflict patterns in sub-Saharan Africa evolve until the middle of the 21st century? Africa is recognized as a particularly vulnerable continent to environmental and climate change since a large portion of its population is poor and reliant on rain-fed agriculture. We use a climate-sensitive approach to model sub-Saharan African violence in the past (geolocated to the nearest settlements) and then forecast future violence using sociopolitical factors such as population size and political rights (governance), coupled with temperature anomalies. Our baseline model is calibrated using 1° gridded monthly data from 1980 to 2012 at a finer spatio-temporal resolution than existing conflict forecasts. We present multiple forecasts of violence under alternative climate change scenarios (optimistic and current global trajectories), of political rights scenarios (improvement and decline), and population projections (low and high fertility). We evaluate alternate shared socio-economic pathways (SSPs) by plotting violence forecasts over time and by detailed mapping of recent and future levels of violence by decade. The forecasts indicate that a growing population and rising temperatures will lead to higher levels of violence in sub-Saharan Africa if political rights do not improve. If political rights continue to improve at the same rate as observed over the last three decades, there is reason for optimism that overall levels of violence will hold steady or even decline in Africa, in spite of projected population increases and rising temperatures.},
	language = {en},
	number = {2},
	urldate = {2019-06-10},
	journal = {Journal of Peace Research},
	author = {Witmer, Frank DW and Linke, Andrew M and O’Loughlin, John and Gettelman, Andrew and Laing, Arlene},
	month = mar,
	year = {2017},
	pages = {175--192},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\VS2FU84H\\Witmer et al. - 2017 - Subnational violent conflict forecasts for sub-Sah.pdf:application/pdf}
}

@article{schutte2017,
	title = {Regions at {Risk}: {Predicting} {Conflict} {Zones} in {African} {Insurgencies}*},
	volume = {5},
	issn = {2049-8470, 2049-8489},
	shorttitle = {Regions at {Risk}},
	url = {http://www.cambridge.org/core/journals/political-science-research-and-methods/article/regions-at-risk-predicting-conflict-zones-in-african-insurgencies/4DCDBA2BCC8B4E3D5057A2C37DDB2BD6},
	doi = {10.1017/psrm.2015.84},
	abstract = {A method for predicting conflict zones in civil wars based on point process models is presented in this paper. Instead of testing the validity of specific theoretical conjectures about the determinants of violence in a causal framework, this paper builds on classic literature and a wide body of recent studies to predict conflict zones based on a series of geographic conditions. Using an innovative cross-validation design, the study shows that the quantitative research program on the micro-foundations of violence in civil conflict has crafted generalizable insights permitting out-of-sample predictions of conflict zones. The study region is delimited to ten countries in Sub-Saharan Africa that experienced full-blown insurgencies in the post-Cold War era.},
	language = {en},
	number = {3},
	urldate = {2019-06-10},
	journal = {Political Science Research and Methods},
	author = {Schutte, Sebastian},
	month = jul,
	year = {2017},
	pages = {447--465},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\QKLYUVXP\\Schutte - 2017 - Regions at Risk Predicting Conflict Zones in Afri.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\CULF9MUJ\\4DCDBA2BCC8B4E3D5057A2C37DDB2BD6.html:text/html}
}

@article{hegre2019,
	title = {{ViEWS}: {A} political violence early-warning system},
	volume = {56},
	issn = {0022-3433},
	shorttitle = {{ViEWS}},
	url = {https://doi.org/10.1177/0022343319823860},
	doi = {10.1177/0022343319823860},
	abstract = {This article presents ViEWS – a political violence early-warning system that seeks to be maximally transparent, publicly available, and have uniform coverage, and sketches the methodological innovations required to achieve these objectives. ViEWS produces monthly forecasts at the country and subnational level for 36 months into the future and all three UCDP types of organized violence: state-based conflict, non-state conflict, and one-sided violence in Africa. The article presents the methodology and data behind these forecasts, evaluates their predictive performance, provides selected forecasts for October 2018 through October 2021, and indicates future extensions. ViEWS is built as an ensemble of constituent models designed to optimize its predictions. Each of these represents a theme that the conflict research literature suggests is relevant, or implements a specific statistical/machine-learning approach. Current forecasts indicate a persistence of conflict in regions in Africa with a recent history of political violence but also alert to new conflicts such as in Southern Cameroon and Northern Mozambique. The subsequent evaluation additionally shows that ViEWS is able to accurately capture the long-term behavior of established political violence, as well as diffusion processes such as the spread of violence in Cameroon. The performance demonstrated here indicates that ViEWS can be a useful complement to non-public conflict-warning systems, and also serves as a reference against which future improvements can be evaluated.},
	language = {en},
	number = {2},
	urldate = {2019-06-10},
	journal = {Journal of Peace Research},
	author = {Hegre, Håvard and Allansson, Marie and Basedau, Matthias and Colaresi, Michael and Croicu, Mihai and Fjelde, Hanne and Hoyles, Frederick and Hultman, Lisa and Högbladh, Stina and Jansen, Remco and Mouhleb, Naima and Muhammad, Sayyed Auwn and Nilsson, Desirée and Nygård, Håvard Mokleiv and Olafsdottir, Gudlaug and Petrova, Kristina and Randahl, David and Rød, Espen Geelmuyden and Schneider, Gerald and von Uexkull, Nina and Vestby, Jonas},
	month = mar,
	year = {2019},
	pages = {155--174},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\CW8LSPAJ\\Hegre et al. - 2019 - ViEWS A political violence early-warning system.pdf:application/pdf}
}

@article{saiya2019,
	title = {Comparing {Classification} {Trees} to {Discern} {Patterns} of {Terrorism}*},
	volume = {100},
	copyright = {© 2019 by the Southwestern Social Science Association},
	issn = {1540-6237},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/ssqu.12629},
	doi = {10.1111/ssqu.12629},
	abstract = {Objective Though applied widely in the fields of medicine, finance, ecology, psychology, and computer science, machine learning algorithmic-based methods are a relatively novel approach to social scientific analysis that have yet to be extensively applied. Yet as we argue in this article, a specific form of algorithmic analysis known as C4.5 classification trees has much to offer social analysis and, specifically, the study of social and political violence. Method This article describes four novel classification model comparison techniques for the C4.5 classification method and applies them to the study of terrorism. Results Our state-level analysis suggests that there is something fundamentally different in the targeting choices of religious and secular terrorists. Conclusion This analysis highlights the ability of classification trees to heighten our understanding of terrorism and even provide recommendations to policymakers for avoiding future attacks.},
	language = {en},
	number = {4},
	urldate = {2019-06-10},
	journal = {Social Science Quarterly},
	author = {Saiya, Nilay and Scime, Anthony},
	year = {2019},
	pages = {1420--1444},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\CWPNPGRP\\Saiya and Scime - 2019 - Comparing Classification Trees to Discern Patterns.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\P6UDL3Q6\\ssqu.html:text/html}
}

@article{sundberg2013,
	title = {Introducing the {UCDP} {Georeferenced} {Event} {Dataset}},
	volume = {50},
	issn = {0022-3433, 1460-3578},
	url = {http://journals.sagepub.com/doi/10.1177/0022343313484347},
	doi = {10.1177/0022343313484347},
	abstract = {This article presents the UCDP Georeferenced Event Dataset (UCDP GED). The UCDP GED is an event dataset that disaggregates three types of organized violence (state-based conflict, non-state conflict, and one-sided violence) both spatially and temporally. Each event – defined as an instance of organized violence with at least one fatality –comes with date, geographical location, and identifiers that allow the dataset to be linked to and merged with other UCDP datasets. The first version of the dataset covers events of fatal violence on the African continent between 1989 and 2010. This article, firstly, introduces the rationale for the new dataset, and explains the basic coding procedures as well as the quality controls. Secondly, we discuss some of the data’s potential weaknesses in representing the universe of organized violence, as well as some potential biases induced by the operationalizations. Thirdly, we provide an example of how the data can be used, by illustrating the association between cities and organized violence, taking population density into account. The UCDP GED is a useful resource for conflict analyses below the state and country-year levels, and can provide us with new insights into the geographical determinants and temporal sequencing of warfare and violence.},
	language = {en},
	number = {4},
	urldate = {2019-06-11},
	journal = {Journal of Peace Research},
	author = {Sundberg, Ralph and Melander, Erik},
	month = jul,
	year = {2013},
	pages = {523--532},
	file = {Sundberg and Melander - 2013 - Introducing the UCDP Georeferenced Event Dataset.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\UBI7DIRR\\Sundberg and Melander - 2013 - Introducing the UCDP Georeferenced Event Dataset.pdf:application/pdf}
}

@article{shaver2019,
	title = {Terrain ruggedness and land cover: {Improved} data for most research designs},
	volume = {36},
	issn = {0738-8942, 1549-9219},
	shorttitle = {Terrain ruggedness and land cover},
	url = {http://journals.sagepub.com/doi/10.1177/0738894216659843},
	doi = {10.1177/0738894216659843},
	abstract = {Existing arguments about the effect of terrain on intrastate and interstate violence are more varied than the data sources widely used to test such relationships. We introduce precise georeferenced data on terrain ruggedness and land cover globally at the national, provincial, and 131 km grid-square levels. Accordingly, the data are readily applicable to a wide range of research designs, including cross-national, sub-national and single-country designs, as well as any study that uses geographic information system data. We demonstrate the utility of the data with replication of Miguel et al. (2004, Journal of Political Economy 112(4): 725–753) and produce new findings leveraging both the ruggedness and land cover data.},
	language = {en},
	number = {2},
	urldate = {2019-06-23},
	journal = {Conflict Management and Peace Science},
	author = {Shaver, Andrew and Carter, David B. and Shawa, Tsering Wangyal},
	month = mar,
	year = {2019},
	pages = {191--218},
	file = {Shaver et al. - 2019 - Terrain ruggedness and land cover Improved data f.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\YRK7JENQ\\Shaver et al. - 2019 - Terrain ruggedness and land cover Improved data f.pdf:application/pdf}
}

@article{levine2008,
	title = {A {Critical} {Assessment} of {Null} {Hypothesis} {Significance} {Testing} in {Quantitative} {Communication} {Research}},
	volume = {34},
	issn = {0360-3989, 1468-2958},
	url = {https://academic.oup.com/hcr/article/34/2/171-187/4210725},
	doi = {10.1111/j.1468-2958.2008.00317.x},
	language = {en},
	number = {2},
	urldate = {2019-06-26},
	journal = {Human Communication Research},
	author = {Levine, Timothy R. and Weber, René and Hullett, Craig and Park, Hee Sun and Lindsey, Lisa L. Massi},
	month = apr,
	year = {2008},
	pages = {171--187},
	file = {Levine et al. - 2008 - A Critical Assessment of Null Hypothesis Significa.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\5KRKCD8D\\Levine et al. - 2008 - A Critical Assessment of Null Hypothesis Significa.pdf:application/pdf}
}

@article{gelman2014,
	title = {The {Statistical} {Crisis} in {Science}},
	volume = {102},
	issn = {0003-0996},
	url = {http://search.proquest.com/docview/1627946025?rfr_id=info%3Axri%2Fsid%3Aprimo},
	abstract = {[...]on: A single overarching research hypothesisin this case, the idea that issue context interacts with political partisanship to affect mathematical problem-solving skills-corresponds to many possible choices of a decision variable. How to Test a Hypothesis In general, we could think of four classes of procedures for hypothesis testing: (1) a simple classical test based on a unique test statistic, T, which when applied to the observed data yields T(y), where y represents the data; (2) a classical test prechosen from a set of possible tests, yielding T(y; p), with preregistered (p (for example, cp might correspond to choices of control variables in a regression, transformations, the decision of which main effect or interaction to focus on); (3) researcher degrees of freedom without fishing, which consists of computing a single test based on the data, but in an environment where a different test would have been performed given different data; the result of such a course is T(y; tp(y)), where the function c({\textgreater}{\textgreater}) is observed in the observed case. In the hypothetical example presented earlier, finding a difference in the healthcare context might be taken as evidence that that is the most important context in which to explore differences.{\textbackslash}n One can follow up an open-ended analysis with prepublication replication, which is related to the idea of external validation, popular in statistics and computer science.},
	language = {English},
	number = {6},
	urldate = {2019-06-26},
	journal = {American Scientist},
	author = {Gelman, Andrew and Loken, Eric},
	year = {2014},
	keywords = {Computers, Data processing, Environmental factors, Problem solving, Replication, Statistics, Transformation},
	pages = {460--465},
	file = {Full Text Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\U25BSIDS\\1.html:text/html;Gelman and Loken - 2014 - The Statistical Crisis in Science.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\YHBEQRYS\\Gelman and Loken - 2014 - The Statistical Crisis in Science.pdf:application/pdf}
}

@article{hainmueller2014a,
	title = {Kernel {Regularized} {Least} {Squares}: {Reducing} {Misspecification} {Bias} with a {Flexible} and {Interpretable} {Machine} {Learning} {Approach}},
	volume = {22},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Kernel {Regularized} {Least} {Squares}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198700013668/type/journal_article},
	doi = {10.1093/pan/mpt019},
	abstract = {We propose the use of Kernel Regularized Least Squares (KRLS) for social science modeling and inference problems. KRLS borrows from machine learning methods designed to solve regression and classification problems without relying on linearity or additivity assumptions. The method constructs a flexible hypothesis space that uses kernels as radial basis functions and finds the best-fitting surface in this space by minimizing a complexity-penalized least squares problem. We argue that the method is well-suited for social science inquiry because it avoids strong parametric assumptions, yet allows interpretation in ways analogous to generalized linear models while also permitting more complex interpretation to examine nonlinearities, interactions, and heterogeneous effects. We also extend the method in several directions to make it more effective for social inquiry, by (1) deriving estimators for the pointwise marginal effects and their variances, (2) establishing unbiasedness, consistency, and asymptotic normality of the KRLS estimator under fairly general conditions, (3) proposing a simple automated rule for choosing the kernel bandwidth, and (4) providing companion software. We illustrate the use of the method through simulations and empirical examples.},
	language = {en},
	number = {2},
	urldate = {2019-06-27},
	journal = {Political Analysis},
	author = {Hainmueller, Jens and Hazlett, Chad},
	year = {2014},
	pages = {143--168},
	file = {Hainmueller and Hazlett - 2014 - Kernel Regularized Least Squares Reducing Misspec.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\M737SNPG\\Hainmueller and Hazlett - 2014 - Kernel Regularized Least Squares Reducing Misspec.pdf:application/pdf}
}

@book{gailmard2014,
	address = {New York},
	title = {Statistical {Modeling} and {Inference} for {Social} {Science}},
	publisher = {Cambridge University Press},
	author = {Gailmard, Sean},
	year = {2014}
}

@article{gross2015,
	title = {Testing {What} {Matters} ({If} {You} {Must} {Test} at {All}): {A} {Context}-{Driven} {Approach} to {Substantive} and {Statistical} {Significance}: {TESTING} {WHAT} {MATTERS}},
	volume = {59},
	issn = {00925853},
	shorttitle = {Testing {What} {Matters} ({If} {You} {Must} {Test} at {All})},
	url = {http://doi.wiley.com/10.1111/ajps.12149},
	doi = {10.1111/ajps.12149},
	language = {en},
	number = {3},
	urldate = {2019-06-27},
	journal = {American Journal of Political Science},
	author = {Gross, Justin H.},
	month = jul,
	year = {2015},
	pages = {775--788},
	file = {Gross - 2015 - Testing What Matters (If You Must Test at All) A .pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\RFKK8LRJ\\Gross - 2015 - Testing What Matters (If You Must Test at All) A .pdf:application/pdf}
}

@article{meehl1979,
	title = {Theoretical risks and tabular asterisks: {Sir} {Karl}, {Sir} {Ronald}, and the slow progress of soft psychology.},
	volume = {46},
	issn = {1939-2117},
	shorttitle = {Theoretical risks and tabular asterisks},
	url = {http://psycnet.apa.org/fulltext/1979-25042-001.pdf},
	doi = {10.1037/0022-006X.46.4.806},
	number = {4},
	urldate = {2019-06-27},
	journal = {Journal of Consulting and Clinical Psychology},
	author = {Meehl, Paul E.},
	year = {1979},
	pages = {806},
	file = {Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\UL7T7QG4\\1979-25042-001.pdf:application/pdf}
}

@book{james2017,
	address = {New York},
	edition = {1st ed. 2013, Corr. 7th printing 2017 edition},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R}},
	isbn = {978-1-4614-7137-0},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
	language = {English},
	publisher = {Springer},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	month = sep,
	year = {2017}
}

@article{samii2016,
	title = {Retrospective {Causal} {Inference} with {Machine} {Learning} {Ensembles}: {An} {Application} to {Anti}-recidivism {Policies} in {Colombia}},
	volume = {24},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Retrospective {Causal} {Inference} with {Machine} {Learning} {Ensembles}},
	url = {http://www.cambridge.org/core/journals/political-analysis/article/retrospective-causal-inference-with-machine-learning-ensembles-an-application-to-antirecidivism-policies-in-colombia/B27477770599A4CE0ACB9204685EA95B},
	doi = {10.1093/pan/mpw019},
	abstract = {We present new methods to estimate causal effects retrospectively from micro data with the assistance of a machine learning ensemble. This approach overcomes two important limitations in conventional methods like regression modeling or matching: (i) ambiguity about the pertinent retrospective counterfactuals and (ii) potential misspecification, overfitting, and otherwise bias-prone or inefficient use of a large identifying covariate set in the estimation of causal effects. Our method targets the analysis toward a well-defined “retrospective intervention effect” based on hypothetical population interventions and applies a machine learning ensemble that allows data to guide us, in a controlled fashion, on how to use a large identifying covariate set. We illustrate with an analysis of policy options for reducing ex-combatant recidivism in Colombia.},
	language = {en},
	number = {4},
	urldate = {2019-06-28},
	journal = {Political Analysis},
	author = {Samii, Cyrus and Paler, Laura and Daly, Sarah Zukerman},
	year = {2016},
	pages = {434--456},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\8GJSYCLY\\Samii et al. - Retrospective Causal Inference with Machine Learni.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\S47IC5KQ\\B27477770599A4CE0ACB9204685EA95B.html:text/html}
}

@article{keele2016b,
	title = {Treating {Time} with {All} {Due} {Seriousness}},
	volume = {24},
	issn = {1047-1987, 1476-4989},
	url = {http://www.cambridge.org/core/journals/political-analysis/article/treating-time-with-all-due-seriousness/6819BB223EB54EF830FCE7065FBFF965},
	doi = {10.1093/pan/mpv031},
	abstract = {In this article, we highlight three points. First, we counter Grant and Lebo's claim that the error correction model (ECM) cannot be applied to stationary data. We maintain that when data are properly stationary, the ECM is an entirely appropriate model. We clarify that for a model to be properly stationary, it must be balanced. Second, we contend that while fractional integration techniques can be useful, they also have important weaknesses, especially when applied to many time series typical in political science. We also highlight two related but often ignored complications in time series: low power and overfitting. We argue that the statistical tests used in time-series analyses have little power to detect differences in many of the sample sizes typical in political science. Moreover, given the small sample sizes, many analysts overfit their time-series models. Overfitting occurs when a statical model describes random error or noise instead of the underlying relationship. We argue that the results in the Grant and Lebo replications could easily be a function of overfitting.},
	language = {en},
	number = {1},
	urldate = {2019-06-28},
	journal = {Political Analysis},
	author = {Keele, Luke and Linn, Suzanna and Webb, Clayton McLaughlin},
	year = {2016},
	pages = {31--41},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\U72VBHPQ\\Keele et al. - 2016 - Treating Time with All Due Seriousness.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\W2KA8FHI\\6819BB223EB54EF830FCE7065FBFF965.html:text/html}
}

@article{breiman2001a,
	title = {Statistical {Modeling}: {The} {Two} {Cultures}},
	volume = {16},
	issn = {0883-4237},
	shorttitle = {Statistical {Modeling}},
	url = {http://www.jstor.org/stable/2676681},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	number = {3},
	urldate = {2019-06-28},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	year = {2001},
	pages = {199--215},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\XNZWD2CC\\Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:application/pdf}
}

@article{landwehr1984,
	title = {Graphical {Methods} for {Assessing} {Logistic} {Regression} {Models}},
	volume = {79},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1984.10477062},
	doi = {10.1080/01621459.1984.10477062},
	abstract = {In ordinary linear regression, graphical diagnostic displays can be very useful for detecting and examining anomalous features in the fit of a model to data. For logistic regression models, the discreteness of binary data makes it difficult to interpret such displays. Modifications and extensions of linear model displays lead to three methods for diagnostic checking of logistic regression models. Local mean deviance plots are useful for detecting overall lack of fit. Empirical probability plots help point out isolated departures from the fitted model. Partial residual plots, when smoothed to show underlying structure, help identify specific causes of lack of fit. These methods are illustrated through the analyses of simulated and real data.},
	number = {385},
	urldate = {2019-06-28},
	journal = {Journal of the American Statistical Association},
	author = {Landwehr, James M. and Pregibon, Daryl and Shoemaker, Anne C.},
	month = mar,
	year = {1984},
	keywords = {Binary data, Goodness of fit, Near neighbors, Partial residual, Probability plot, Residual analysis},
	pages = {61--71},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\M5UQWVAL\\Landwehr et al. - 1984 - Graphical Methods for Assessing Logistic Regressio.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\WWGDP8MV\\01621459.1984.html:text/html}
}

@article{bickel2006,
	title = {Tailor-{Made} {Tests} for {Goodness} of {Fit} to {Semiparametric} {Hypotheses}},
	volume = {34},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/25463434},
	abstract = {We introduce a new framework for constructing tests of general semiparametric hypotheses which have nontrivial power on the \$n{\textasciicircum}\{-1/2\}\$ scale in every direction, and can be tailored to put substantial power on alternatives of importance. The approach is based on combining test statistics based on stochastic processes of score statistics with bootstrap critical values.},
	number = {2},
	urldate = {2019-06-28},
	journal = {The Annals of Statistics},
	author = {Bickel, Peter J. and Ritov, Ya'acov and Stoker, Thomas M.},
	year = {2006},
	pages = {721--741},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\D6LH9RUE\\Bickel et al. - 2006 - Tailor-Made Tests for Goodness of Fit to Semiparam.pdf:application/pdf}
}

@article{stone1974,
	title = {Cross-{Validatory} {Choice} and {Assessment} of {Statistical} {Predictions}},
	volume = {36},
	issn = {0035-9246},
	url = {http://www.jstor.org/stable/2984809},
	abstract = {A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
	number = {2},
	urldate = {2019-06-28},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Stone, M.},
	year = {1974},
	pages = {111--147},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\9A5P2TLY\\Stone - 1974 - Cross-Validatory Choice and Assessment of Statisti.pdf:application/pdf}
}

@article{wasserstein2016a,
	title = {The {ASA} {Statement} on p-values: {Context}, {Process}, and {Purpose}},
	volume = {70},
	issn = {0003-1305, 1537-2731},
	shorttitle = {The {ASA} {Statement} on \textit{p} -{Values}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108},
	doi = {10.1080/00031305.2016.1154108},
	language = {en},
	number = {2},
	urldate = {2019-06-28},
	journal = {The American Statistician},
	author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
	month = apr,
	year = {2016},
	pages = {129--133},
	file = {Wasserstein and Lazar - 2016 - The ASA Statement on ipi -Values Context, Pr.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\SSEU6PFY\\Wasserstein and Lazar - 2016 - The ASA Statement on ipi -Values Context, Pr.pdf:application/pdf}
}

@incollection{meehl1986,
	address = {Chicago},
	title = {What {Social} {Scientists} {Don}’t {Understand}},
	language = {en},
	booktitle = {Metatheory in social science:	{Pluralisms} and	subjectivities},
	publisher = {University of Chicago Press},
	author = {Meehl, P E},
	year = {1986},
	pages = {24},
	file = {Meehl - What Social Scientists Don’t Understand.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\KG4TLR5Q\\Meehl - What Social Scientists Don’t Understand.pdf:application/pdf}
}

@book{dougherty2011a,
	address = {Oxford ; New York},
	edition = {4 edition},
	title = {Introduction to {Econometrics}},
	isbn = {978-0-19-956708-9},
	abstract = {Retaining the student-friendly approach of previous editions, Introduction to Econometrics, Fourth Edition, uses clear and simple mathematics notation and step-by step explanations of mathematical proofs to help students thoroughly grasp the subject. Extensive practical exercises throughout--including fifty exercises on the same dataset--build students' confidence and provide them with hands-on practice in applying techniques.NEW TO THE FOURTH EDITION:* An expanded review section at the beginning of the book offers a more comprehensive guide to all of the statistical concepts needed to study econometrics* Additional exercises provide students with even more opportunities to put theory into practice* More Monte Carlo simulations help students use visualization to understand the math* New final sections at the end of each chapter contain summaries and non-technical introductions to more advanced topicsAn updated and expanded Companion Website contains resources for students and instructors:For students:* Data sets* Gretl, a free econometrics software application* PowerPoint-based slides with explanations* A study guideFor instructors:* Instructor manuals for the text and data sets that detail the exercises and their solutions* PowerPoint-based slides* A "Contact the Author" link},
	language = {English},
	publisher = {Oxford University Press},
	author = {Dougherty, Christopher},
	month = apr,
	year = {2011}
}

@article{brandt2014,
	title = {Evaluating forecasts of political conflict dynamics},
	volume = {30},
	issn = {0169-2070},
	url = {http://www.sciencedirect.com/science/article/pii/S0169207014000612},
	doi = {10.1016/j.ijforecast.2014.03.014},
	abstract = {There is considerable interest today in the forecasting of conflict dynamics. Commonly, the root mean square error and other point metrics are used to evaluate the forecasts from such models. However, conflict processes are non-linear, so these point metrics often do not produce adequate evaluations of the calibration and sharpness of the forecast models. Forecast density evaluation improves the model evaluation. We review tools for density evaluation, including continuous rank probability scores, verification rank histograms, and sharpness plots. The usefulness of these tools for evaluating conflict forecasting models is explained. We illustrate this, first, in a comparison of several time series models’ forecasts of simulated data from a Markov-switching process, and second, in a comparison of several models’ abilities to forecast conflict dynamics in the Cross Straits. These applications show the pitfalls of relying on point metrics alone for evaluating the quality of conflict forecasting models. As in other fields, it is more useful to employ a suite of tools. A non-linear vector autoregressive model emerges as the model which is best able to forecast conflict dynamics between China and Taiwan.},
	number = {4},
	urldate = {2019-06-28},
	journal = {International Journal of Forecasting},
	author = {Brandt, Patrick T. and Freeman, John R. and Schrodt, Philip A.},
	month = oct,
	year = {2014},
	keywords = {Bayesian, Conflict dynamics, Density evaluation, Scoring rules, Time series, Verification rank histogram},
	pages = {944--962},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\DFHHDMS4\\Brandt et al. - 2014 - Evaluating forecasts of political conflict dynamic.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\BQZZ4TF8\\S0169207014000612.html:text/html}
}

@article{singer1973,
	title = {The peace researcher and foreign policy prediction},
	volume = {21},
	url = {https://www.taylorfrancis.com/},
	abstract = {With all of the foolishness that has characterized the “futures” game over the past
decade or so, it is clearly time to put this question on the agenda of a},
	language = {en},
	urldate = {2019-06-29},
	journal = {Papers of the Peace Science Society},
	author = {Singer, J. David},
	year = {1973},
	doi = {10.4324/9780203128398-18},
	pages = {1:13},
	file = {Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\Z3ILBE9W\\9780203128398-18.html:text/html}
}

@article{schneider2010,
	title = {Exploring the {Past}, {Anticipating} the {Future}: {A} {Symposium}},
	volume = {12},
	issn = {15219488, 14682486},
	shorttitle = {Exploring the {Past}, {Anticipating} the {Future}},
	url = {https://academic.oup.com/isr/article-lookup/doi/10.1111/j.1468-2486.2009.00909.x},
	doi = {10.1111/j.1468-2486.2009.00909.x},
	language = {en},
	number = {1},
	urldate = {2019-06-29},
	journal = {International Studies Review},
	author = {Schneider, Gerald and Gleditsch, Nils Petter and Carey, Sabine C.},
	month = mar,
	year = {2010},
	pages = {1--7},
	file = {Schneider et al. - 2010 - Exploring the Past, Anticipating the Future A Sym.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\PGEE56TQ\\Schneider et al. - 2010 - Exploring the Past, Anticipating the Future A Sym.pdf:application/pdf}
}

@article{hegre2017,
	title = {Introduction: {Forecasting} in peace research},
	volume = {54},
	issn = {0022-3433},
	shorttitle = {Introduction},
	url = {https://doi.org/10.1177/0022343317691330},
	doi = {10.1177/0022343317691330},
	abstract = {Prediction and forecasting have now fully reached peace and conflict research. We define forecasting as predictions about unrealized outcomes given model estimates from realized data, and predictions more generally as the assignment of probability distributions to realized or unrealized outcomes. Increasingly, scholars present within- and out-of-sample prediction results in their publications and sometimes even forecasts for unrealized, future outcomes. The articles in this special issue demonstrate the ability of current approaches to forecast events of interest and contributes to the formulation of best practices for forecasting within peace research. We highlight the role of forecasting for theory evaluation and as a bridge between academics and policymakers, summarize the contributions in the special issue, and provide some thoughts on how research on forecasting in peace research should proceed. We suggest some best practices, noting the importance of theory development, interpretability of models, replicability of results, and data collection.},
	language = {en},
	number = {2},
	urldate = {2019-06-29},
	journal = {Journal of Peace Research},
	author = {Hegre, Håvard and Metternich, Nils W and Nygård, Håvard Mokleiv and Wucherpfennig, Julian},
	month = mar,
	year = {2017},
	pages = {113--124},
	file = {SAGE PDF Full Text:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\5J8MYSK6\\Hegre et al. - 2017 - Introduction Forecasting in peace research.pdf:application/pdf}
}

@article{beck2000,
	title = {Improving {Quantitative} {Studies} of {International} {Conflict}: {A} {Conjecture}},
	volume = {94},
	issn = {0003-0554},
	shorttitle = {Improving {Quantitative} {Studies} of {International} {Conflict}},
	url = {http://www.jstor.org/stable/2586378},
	doi = {10.2307/2586378},
	abstract = {We address a well-known but infrequently discussed problem in the quantitative study of international conflict: Despite immense data collections, prestigious journals, and sophisticated analyses, empirical findings in the literature on international conflict are often unsatisfying. Many statistical results change from article to article and specification to specification. Accurate forecasts are nonexistent. In this article we offer a conjecture about one source of this problem: The causes of conflict, theorized to be important but often found to be small or ephemeral, are indeed tiny for the vast majority of dyads, but they are large, stable, and replicable wherever the ex ante probability of conflict is large. This simple idea has an unexpectedly rich array of observable implications, all consistent with the literature. We directly test our conjecture by formulating a statistical model that includes its critical features. Our approach, a version of a "neural network" model, uncovers some interesting structural features of international conflict and, as one evaluative measure, forecasts substantially better than any previous effort. Moreover, this improvement comes at little cost, and it is easy to evaluate whether the model is a statistical improvement over the simpler models commonly used.},
	number = {1},
	urldate = {2019-06-30},
	journal = {The American Political Science Review},
	author = {Beck, Nathaniel and King, Gary and Zeng, Langche},
	year = {2000},
	pages = {21--35},
	file = {JSTOR Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\HKM5HJR2\\Beck et al. - 2000 - Improving Quantitative Studies of International Co.pdf:application/pdf}
}

@article{fafchamps2017,
	title = {Using {Split} {Samples} to {Improve} {Inference} on {Causal} {Effects}},
	volume = {25},
	issn = {1047-1987, 1476-4989},
	url = {http://www.cambridge.org/core/journals/political-analysis/article/using-split-samples-to-improve-inference-on-causal-effects/6727EF63175DF517BF56EC64EFF3E807},
	doi = {10.1017/pan.2017.22},
	abstract = {We discuss a statistical procedure to carry out empirical research that combines recent insights about preanalysis plans (PAPs) and replication. Researchers send their datasets to an independent third party who randomly generates training and testing samples. Researchers perform their analysis on the training sample and are able to incorporate feedback from both colleagues, editors, and referees. Once the paper is accepted for publication the method is applied to the testing sample and it is those results that are published. Simulations indicate that, under empirically relevant settings, the proposed method delivers more power than a PAP. The effect mostly operates through a lower likelihood that relevant hypotheses are left untested. The method appears better suited for exploratory analyses where there is significant uncertainty about the outcomes of interest. We do not recommend using the method in situations where the treatment are very costly and thus the available sample size is limited. An interpretation of the method is that it allows researchers to perform direct replication of their work. We also discuss a number of practical issues about the method’s feasibility and implementation.},
	language = {en},
	number = {4},
	urldate = {2019-06-30},
	journal = {Political Analysis},
	author = {Fafchamps, Marcel and Labonne, Julien},
	month = oct,
	year = {2017},
	pages = {465--482},
	file = {Full Text PDF:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\3MPV9G3P\\Fafchamps and Labonne - 2017 - Using Split Samples to Improve Inference on Causal.pdf:application/pdf;Snapshot:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\NJ8EGTDY\\6727EF63175DF517BF56EC64EFF3E807.html:text/html}
}

@article{beger2014,
	title = {Ensemble forecasting of irregular leadership change},
	volume = {1},
	issn = {2053-1680, 2053-1680},
	url = {http://journals.sagepub.com/doi/10.1177/2053168014557511},
	doi = {10.1177/2053168014557511},
	abstract = {Using updated Archigos Data, as well as structural and event data, we construct a split-population duration model of irregular leadership changes. These are leadership changes that occur outside of the normal, legal framework for leadership transitions. Our model was estimated in March 2014 and produced probability estimates of leadership changes in many countries in the world. We used a wisdom-of-the-crowds approach to combining estimates from various different models. Ukraine and Thailand are among those in which we had the highest predictions for irregular change of leaders.},
	language = {en},
	number = {3},
	urldate = {2019-06-30},
	journal = {Research \& Politics},
	author = {Beger, Andreas and Dorff, Cassy L and Ward, Michael D},
	month = oct,
	year = {2014},
	pages = {205316801455751},
	file = {Beger et al. - 2014 - Ensemble forecasting of irregular leadership chang.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\PJ9HGNRZ\\Beger et al. - 2014 - Ensemble forecasting of irregular leadership chang.pdf:application/pdf}
}

@article{hegre2006,
	title = {Sensitivity {Analysis} of {Empirical} {Results} on {Civil} {War} {Onset}},
	volume = {50},
	issn = {0022-0027, 1552-8766},
	url = {http://journals.sagepub.com/doi/10.1177/0022002706289303},
	doi = {10.1177/0022002706289303},
	language = {en},
	number = {4},
	urldate = {2019-07-01},
	journal = {Journal of Conflict Resolution},
	author = {Hegre, Håvard and Sambanis, Nicholas},
	month = aug,
	year = {2006},
	pages = {508--535},
	file = {Hegre and Sambanis - 2006 - Sensitivity Analysis of Empirical Results on Civil.pdf:C\:\\Users\\Christopher\\Documents\\zotero\\storage\\Z5N84LB2\\Hegre and Sambanis - 2006 - Sensitivity Analysis of Empirical Results on Civil.pdf:application/pdf}
}

@article{blair2019,
	title = {Forecasting {Civil} {Wars}: {Theory} and {Structure} in an {Age} of ‘{Big} {Data}’ and {Machine} {Learning}},
	url = {http://egap.org/registration/1760},
	journal = {Working Paper.},
	author = {Blair, Robert and Sambanis, Nicholas},
	year = {2019}
}